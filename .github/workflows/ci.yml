name: CI
on:
  push:
  pull_request:
  workflow_dispatch:
    inputs:
      rollback_model:
        description: MLflow model name to rollback
        required: false
        default: bi-encoder
      rollback_version:
        description: Version to set to Production
        required: false
        default: ""

jobs:
  test:
    runs-on: ubuntu-latest
    env:
      MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_URL }}
      MLFLOW_TRACKING_USERNAME: ${{ secrets.MLFLOW_USER }}
      MLFLOW_TRACKING_PASSWORD: ${{ secrets.MLFLOW_PASS }}
      MLFLOW_MODEL_NAME: bi-encoder
      MLFLOW_MODEL_REF: models:/bi-encoder@Staging
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with: { python-version: '3.11', cache: 'pip' }

      - name: Lint (ruff, soft)
        run: |
          python -m pip install -U ruff
          # Hard-fail on syntax/undefined names etc.
          ruff check . --select E9,F63,F7,F82

      - name: Parser tests
        working-directory: AI/services/parser
        run: |
          pip install -r requirements.txt
          pip install pytest
          pytest -q -m "not slow"

      - name: API tests
        working-directory: AI/services/api
        run: |
          pip install -r requirements.txt
          pip install pytest
          pytest -q -m "not slow"

      - name: UI tests (optional)
        working-directory: AI/services/ui
        run: |
          pip install -r requirements.txt || true
          pip install pytest || true
          pytest -q -m "not slow" || true

      - name: Generate parsed.parquet from raw (if present)
        if: ${{ hashFiles('AI/data/raw/**/*.json') != '' && hashFiles('AI/data/interim/parsed.parquet') == '' }}
        working-directory: AI/services/parser
        run: |
          pip install -q -r requirements.txt
          python parse_guidelines.py --raw ../../data/raw --out ../../data/interim

      - name: Create tiny parsed.parquet fixture (fallback)
        if: ${{ hashFiles('AI/data/interim/parsed.parquet') == '' }}
        run: |
          python -m pip install -q pandas pyarrow
          python - <<'PY'
          import pandas as pd, os
          os.makedirs('AI/data/interim', exist_ok=True)
          df = pd.DataFrame([
            {"guideline_id":"g1","group_seq":1,"pos":0,"item_id":"item1","left_neighbor":None,"right_neighbor":"item2"},
            {"guideline_id":"g1","group_seq":1,"pos":1,"item_id":"item2","left_neighbor":"item1","right_neighbor":"item3"},
            {"guideline_id":"g1","group_seq":1,"pos":2,"item_id":"item3","left_neighbor":"item2","right_neighbor":None},
          ])
          df.to_parquet('AI/data/interim/parsed.parquet')
          PY

      - name: Download candidate model from MLflow (optional)
        if: ${{ env.MLFLOW_TRACKING_URI != '' }}
        run: |
          python -m pip install -q mlflow
          rm -rf AI/models/artifacts || true
          mlflow models download -m "$MLFLOW_MODEL_REF" -d AI/models/artifacts

      - name: Evaluate bi-encoder (optional)
        id: eval
        if: ${{ env.MLFLOW_TRACKING_URI != '' && hashFiles('AI/data/interim/parsed.parquet') != '' }}
        run: |
          python -m pip install -q faiss-cpu pandas numpy pyarrow
          python AI/services/trainer-bienc/evaluate_bi.py --in AI/data/interim --artifacts AI/models/artifacts --k 1,3,5,10 | tee eval.txt

      - name: Gate metrics (optional)
        id: metrics
        if: ${{ steps.eval.outcome == 'success' }}
        run: |
          python - <<'PY'
          import re, ast, sys
          txt=open('eval.txt','r',encoding='utf-8').read()
          m=re.search(r'Aggregate: (\{.*\})', txt)
          agg=ast.literal_eval(m.group(1)) if m else {}
          print('Aggregate:', agg)
          ok = (agg.get('recall@1',0)>=0.35 and agg.get('mrr',0)>=0.53)
          print('OK=', ok)
          sys.exit(0 if ok else 1)
          PY

      - name: Set gate output
        id: gate
        run: |
          if [ "${{ steps.metrics.outcome }}" = "success" ]; then echo "ok=true" >> $GITHUB_OUTPUT; else echo "ok=false" >> $GITHUB_OUTPUT; fi
    outputs:
      metrics_ok: ${{ steps.gate.outputs.ok }}

  docker-build:
    runs-on: ubuntu-latest
    needs: test
    steps:
      - uses: actions/checkout@v4
      - name: Build images
        run: |
          docker build -t ai-parser           AI/services/parser
          docker build -t ai-trainer-bienc    AI/services/trainer-bienc
          docker build -t ai-trainer-gnn      AI/services/trainer-gnn
          docker build -t ai-featurizer       AI/services/featurizer
          docker build -t ai-api              AI/services/api
          docker build -t ai-ui               AI/services/ui

  promote-model:
    runs-on: ubuntu-latest
    needs: test
    if: ${{ github.ref == 'refs/heads/main' && needs.test.outputs.metrics_ok == 'true' }}
    env:
      MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_URL }}
      MLFLOW_TRACKING_USERNAME: ${{ secrets.MLFLOW_USER }}
      MLFLOW_TRACKING_PASSWORD: ${{ secrets.MLFLOW_PASS }}
      MLFLOW_ALLOW_PROMOTE: ${{ secrets.MLFLOW_ALLOW_PROMOTE }}
      MLFLOW_MODEL_NAME: bi-encoder
      FROM_STAGE: Staging
      TO_STAGE: Production
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - name: Promote latest Staging to Production
        if: ${{ env.MLFLOW_TRACKING_URI != '' && env.MLFLOW_ALLOW_PROMOTE == 'true' }}
        run: |
          python -m pip install -q mlflow
          python - <<'PY'
          import os
          from mlflow.tracking import MlflowClient
          client = MlflowClient()
          name = os.environ['MLFLOW_MODEL_NAME']
          stg = os.environ['FROM_STAGE']
          ver = client.get_latest_versions(name, [stg])[0].version
          client.transition_model_version_stage(name, ver, os.environ['TO_STAGE'], archive_existing_versions=True)
          print(f"Promoted {name} v{ver} -> {os.environ['TO_STAGE']}")
          PY

  rollback:
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'workflow_dispatch' && inputs.rollback_version != '' }}
    env:
      MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_URL }}
      MLFLOW_TRACKING_USERNAME: ${{ secrets.MLFLOW_USER }}
      MLFLOW_TRACKING_PASSWORD: ${{ secrets.MLFLOW_PASS }}
    steps:
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - name: Rollback Production to specific version
        if: ${{ env.MLFLOW_TRACKING_URI != '' }}
        run: |
          python -m pip install -q mlflow
          mlflow models transition-stage --model-name "${{ inputs.rollback_model }}" --version "${{ inputs.rollback_version }}" --stage Production
