services:
  parser:
    build: ./services/parser
    env_file: .env
    volumes:
      - ./data:/app/data
      - ./models:/app/models
    command: ["python","parse_guidelines.py","--raw","/app/data/raw","--out","/app/data/interim"]

  trainer:
    build: ./services/trainer
    env_file: .env
    depends_on: [parser]
    volumes:
      - ./data:/app/data
      - ./models:/app/models
    command: ["python","train_model.py","--in","/app/data/interim","--out","/app/models/artifacts"]

  api:
    build: ./services/api
    env_file: .env
    depends_on: [trainer]
    ports: ["8000:8000"]
    volumes:
      - ./models:/app/models:ro
  
  featurizer:
    build: ./services/featurizer
    env_file: .env
    depends_on: [parser]
    volumes:
      - ./data:/app/data
      - ./models:/app/models
    command: ["python","featurize_text.py","--in","/app/data/interim","--out","/app/models/artifacts"]

  trainer-bienc:
    profiles: ["train"]           # won't start on plain `up`
    build: ./services/trainer-bienc
    env_file: .env
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - hf_cache:/root/.cache/huggingface   # speed up downloads
    command: ["python","train_bi.py","--in","/app/data/interim","--artifacts","/app/models/artifacts","--base","sentence-transformers/all-MiniLM-L6-v2","--epochs","2","--batch","16"]
    restart: "no"

  ui:
    build: ./services/ui
    env_file: .env
    environment:
      API_BASE_URL: http://api:8000
    depends_on: [api]
    ports: ["8501:8501"]

volumes:
  hf_cache: